{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.ml import UserIdentityConfiguration, MLClient, Input, Output, load_component\n",
    "from azure.ai.ml.dsl import pipeline\n",
    "from azure.ai.ml.entities import Environment\n",
    "from azure.ai.ml.constants import AssetTypes, InputOutputModes\n",
    "from azure.ai.ml.parallel import parallel_run_function, RunFunction\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from datetime import datetime\n",
    "import os\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'USER': 'zacksoenen', 'VSCODE_WSL_EXT_LOCATION': '/mnt/c/Users/zacksoenen/.vscode/extensions/ms-vscode-remote.remote-wsl-0.81.8', 'WT_PROFILE_ID': '{51855cb2-8cce-5362-8f54-464b92b32386}', 'SHLVL': '2', 'HOME': '/home/zacksoenen', 'OLDPWD': '/mnt/c/Users/zacksoenen/AppData/Local/Programs/Microsoft VS Code', 'DBUS_SESSION_BUS_ADDRESS': 'unix:path=/run/user/1000/bus', 'WSL_DISTRO_NAME': 'Ubuntu', 'WAYLAND_DISPLAY': 'wayland-0', 'LOGNAME': 'zacksoenen', 'PULSE_SERVER': 'unix:/mnt/wslg/PulseServer', 'WSL_INTEROP': '/run/WSL/97485_interop', 'NAME': 'Code', '_': '/home/zacksoenen/miniconda3/envs/mm_remote/bin/python', 'TERM': 'xterm-color', 'PATH': '/home/zacksoenen/miniconda3/envs/mm_remote/bin:/home/zacksoenen/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/home/zacksoenen/miniconda3/envs/mm_remote/bin:/home/zacksoenen/miniconda3/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/usr/lib/wsl/lib:/mnt/c/Program Files/Microsoft SDKs/Azure/CLI2/wbin:/mnt/c/Windows/system32:/mnt/c/Windows:/mnt/c/Windows/System32/Wbem:/mnt/c/Windows/System32/WindowsPowerShell/v1.0:/mnt/c/Windows/System32/OpenSSH:/mnt/c/Program Files/Git/cmd:/mnt/c/Users/zacksoenen/AppData/Local/Microsoft/WindowsApps:/mnt/c/Users/zacksoenen/AppData/Local/Programs/Microsoft VS Code/bin:/mnt/c/Users/zacksoenen/AppData/Local/Programs/Hyper/resources/bin:/miniconda3/bin', 'XDG_RUNTIME_DIR': '/run/user/1000/', 'WT_SESSION': '78b66c4d-e2e4-484f-9bb4-115d51cee054', 'DISPLAY': ':0', 'LANG': 'C.UTF-8', 'SHELL': '/usr/bin/zsh', 'VSCODE_SERVER_TAR': '/mnt/c/Users/ZACKSO~1/AppData/Local/Temp/vscode-remote-wsl/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/vscode-server-stable-linux-x64.tar.gz', 'PWD': '/mnt/c/Users/zacksoenen/AppData/Local/Programs/Microsoft VS Code', 'HOSTTYPE': 'x86_64', 'WSL2_GUI_APPS_ENABLED': '1', 'WSLENV': 'ELECTRON_RUN_AS_NODE/w:WT_SESSION:WT_PROFILE_ID:\\n', 'VSCODE_HANDLES_SIGPIPE': 'true', 'ZSH': '/home/zacksoenen/.oh-my-zsh', 'PAGER': 'cat', 'LESS': '-R', 'LSCOLORS': 'Gxfxcxdxbxegedabagacad', 'LS_COLORS': 'rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=00:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.zst=01;31:*.tzst=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.wim=01;31:*.swm=01;31:*.dwm=01;31:*.esd=01;31:*.jpg=01;35:*.jpeg=01;35:*.mjpg=01;35:*.mjpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.webp=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=00;36:*.au=00;36:*.flac=00;36:*.m4a=00;36:*.mid=00;36:*.midi=00;36:*.mka=00;36:*.mp3=00;36:*.mpc=00;36:*.ogg=00;36:*.ra=00;36:*.wav=00;36:*.oga=00;36:*.opus=00;36:*.spx=00;36:*.xspf=00;36:', 'VIRTUAL_ENV_DISABLE_PROMPT': '1', 'CONDA_EXE': '/home/zacksoenen/miniconda3/bin/conda', '_CE_M': '', '_CE_CONDA': '', 'CONDA_PYTHON_EXE': '/home/zacksoenen/miniconda3/bin/python', 'CONDA_SHLVL': '2', 'CONDA_PREFIX': '/home/zacksoenen/miniconda3/envs/mm_remote', 'CONDA_DEFAULT_ENV': 'mm_remote', 'CONDA_PROMPT_MODIFIER': '(mm_remote) ', 'VSCODE_AMD_ENTRYPOINT': 'vs/workbench/api/node/extensionHostProcess', 'VSCODE_HANDLES_UNCAUGHT_ERRORS': 'true', 'VSCODE_NLS_CONFIG': '{\"locale\":\"en\",\"osLocale\":\"en\",\"availableLanguages\":{}}', 'VSCODE_CWD': '/mnt/c/Users/zacksoenen/AppData/Local/Programs/Microsoft VS Code', 'ELECTRON_RUN_AS_NODE': '1', 'VSCODE_IPC_HOOK_CLI': '/run/user/1000/vscode-ipc-34f352a5-569c-4be4-a001-cde094b0bc49.sock', 'APPLICATION_INSIGHTS_NO_DIAGNOSTIC_CHANNEL': '1', 'PYTHONUNBUFFERED': '1', 'CONDA_ROOT': '/home/zacksoenen/miniconda3', 'PYTHONIOENCODING': 'utf-8', 'WORKSPACE_NAME': 'mm-aml-wksp', 'TENANT_ID': '16b3c013-d300-468d-ac64-7eda0820b6d3', 'SUBSCRIPTION_ID': '9a729243-1221-42c5-824c-9e44cb2da98d', 'RESOURCE_GROUP_NAME': 'many-models-rg', 'CONDA_PREFIX_1': '/home/zacksoenen/miniconda3', 'PYDEVD_IPYTHON_COMPATIBLE_DEBUGGING': '1', 'PYDEVD_USE_FRAME_EVAL': 'NO', 'CLICOLOR': '1', 'GIT_PAGER': 'cat', 'MPLBACKEND': 'module://matplotlib_inline.backend_inline', 'AZUREML_CURRENT_CLOUD': 'AzureCloud'}\n"
     ]
    }
   ],
   "source": [
    "# Initialize ML Client\n",
    "load_dotenv(find_dotenv(), override=True)\n",
    "\n",
    "# authenticate\n",
    "credential = DefaultAzureCredential(tenantid=os.environ.get('TENANT_ID'))\n",
    "\n",
    "# Get a handle to the workspace\n",
    "ml_client = MLClient(\n",
    "    credential=credential,\n",
    "    subscription_id = os.environ.get('SUBSCRIPTION_ID'),\n",
    "    resource_group_name = os.environ.get('RESOURCE_GROUP_NAME'),\n",
    "    workspace_name = os.environ.get('WORKSPACE_NAME'),\n",
    ")\n",
    "\n",
    "print(dict(os.environ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use remote environment created in step 1\n",
    "custom_env_name = \"mm-remote-env-py37\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "azureml://subscriptions/9a729243-1221-42c5-824c-9e44cb2da98d/resourcegroups/many-models-rg/workspaces/mm-aml-wksp/datastores/workspaceblobstore/paths/LocalUpload/724411e17666e66d19b8612b775b7707/test_subset.csv\n"
     ]
    }
   ],
   "source": [
    "# Acess data asset\n",
    "data_name = \"oj-sim-sales-test\"\n",
    "test_data_asset = ml_client.data.get(data_name, label='latest')\n",
    "print(test_data_asset.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data preparation component\n",
    "partition_data = load_component(source=\"../src/components/partition_data/partition_data.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_compute_target = \"mm-cpu-cluster\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "azureml_tracking_uri = ml_client.workspaces.get(ml_client.workspace_name).mlflow_tracking_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "many_model_outputs/20240108144658/\n"
     ]
    }
   ],
   "source": [
    "run_time = datetime.today().strftime('%Y%m%d%H%M%S')\n",
    "\n",
    "output_dir = f\"many_model_outputs/{run_time}/\"\n",
    "print(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create parallel inference step\n",
    "# Declare parallel job, with a run_function task\n",
    "many_model_inference_with_partition_keys = parallel_run_function(\n",
    "    name=\"distributed_inference\",\n",
    "    display_name=\"Many Model Predictions\",\n",
    "    description=\"parallel job to batch predict with many models\",\n",
    "    inputs=dict(\n",
    "        data_source=Input(\n",
    "            type=AssetTypes.MLTABLE,\n",
    "            description=\"Input mltable with predefined partition format.\",\n",
    "            mode=InputOutputModes.DIRECT,  # [Important] To use 'partition_keys', input MLTable is required to use 'direct' mode.\n",
    "        ),\n",
    "        drop_cols=Input(\n",
    "            type=\"string\",\n",
    "            description=\"Columns need to be dropped before training. Split by comma.\",\n",
    "        ),\n",
    "        experiment_names=Input(\n",
    "            type=\"string\",\n",
    "            description=\"Name of training experiement(s) to be used to select best model. Split by comma.\",\n",
    "        ),\n",
    "        metric_name=Input(\n",
    "            type=\"string\",\n",
    "            description=\"Name of metric to be used to select best model, to be used in mlflow query. i.e. test_remse\",\n",
    "        ),\n",
    "        date_col=Input(\n",
    "            type=\"string\",\n",
    "            description=\"Name of date column in data\",\n",
    "        ),\n",
    "        tracking_uri=Input(\n",
    "            type=\"string\",\n",
    "            description=\"tracking uri of mlflow server (aml workspace)\",\n",
    "        ),\n",
    "    ),\n",
    "    outputs=dict(\n",
    "        output_dir=Output(\n",
    "            type=AssetTypes.URI_FOLDER,\n",
    "            mode=InputOutputModes.RW_MOUNT,\n",
    "        )\n",
    "    ),\n",
    "    input_data=\"${{inputs.data_source}}\",  # Define which input data will be splitted into mini-batches\n",
    "    partition_keys=[\"Store\",\"Brand\"],  # Use 'partition_keys' as the data division method. This method requires MLTable input with partition setting pre-defined in MLTable artifact.\n",
    "    instance_count=6,  # Use X nodes from compute cluster to run this parallel job.\n",
    "    max_concurrency_per_instance=2,  # Create 2 worker processors in each compute node to execute mini-batches.\n",
    "    error_threshold=-1,  # Monitor the failures of item processed by the gap between mini-batch input count and returns. 'Many model training' scenario doesn't fit this setting and '-1' means ignore counting failure items by mini-batch returns.\n",
    "    mini_batch_error_threshold=5,  # Monitor the failed mini-batch by exception, time out, or null return. When failed mini-batch count is higher than this setting, the parallel job will be marked as 'failed'.\n",
    "    retry_settings=dict(\n",
    "        max_retries=1,  # Define how many retries when mini-batch execution is failed by exception, time out, or null return.\n",
    "        timeout=60,  # Define the timeout in second for each mini-batch execution.\n",
    "    ),\n",
    "    logging_level=\"DEBUG\", # DEBUG, INFO, WARNING, ERROR, ETC\n",
    "    task=RunFunction(\n",
    "        code=\"../src/\",\n",
    "        entry_script=\"parallel_inference.py\",\n",
    "        environment=ml_client.environments.get(custom_env_name, label=\"latest\"),\n",
    "        program_arguments=\"--drop_cols ${{inputs.drop_cols}} \"  # Passthrough input parameters into parallel_train script.\n",
    "        \"--experiment_names ${{inputs.experiment_names}} \"\n",
    "        \"--metric_name ${{inputs.metric_name}} \"\n",
    "        \"--tracking_uri ${{inputs.tracking_uri}} \"\n",
    "        \"--date_col ${{inputs.date_col}} \"\n",
    "        \"--output_dir ${{outputs.output_dir}} \",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "display_name: parallel inference - outpath\n",
      "type: pipeline\n",
      "inputs:\n",
      "  pipeline_input_data:\n",
      "    mode: ro_mount\n",
      "    type: uri_file\n",
      "    path: azureml://subscriptions/9a729243-1221-42c5-824c-9e44cb2da98d/resourcegroups/many-models-rg/workspaces/mm-aml-wksp/datastores/workspaceblobstore/paths/LocalUpload/724411e17666e66d19b8612b775b7707/test_subset.csv\n",
      "jobs:\n",
      "  partition_job:\n",
      "    type: command\n",
      "    inputs:\n",
      "      data_source:\n",
      "        path: ${{parent.inputs.pipeline_input_data}}\n",
      "      partition_keys: Store,Brand\n",
      "    component:\n",
      "      $schema: https://azuremlschemas.azureedge.net/latest/commandComponent.schema.json\n",
      "      name: partition_data\n",
      "      version: '1'\n",
      "      display_name: Partition data by keys\n",
      "      type: command\n",
      "      inputs:\n",
      "        data_source:\n",
      "          type: uri_file\n",
      "        partition_keys:\n",
      "          type: string\n",
      "      outputs:\n",
      "        tabular_output_data:\n",
      "          type: mltable\n",
      "      command: python partition_data.py --data_source ${{inputs.data_source}} --partition_keys\n",
      "        ${{inputs.partition_keys}} --tabular_output_data ${{outputs.tabular_output_data}}\n",
      "      environment: azureml:/subscriptions/9a729243-1221-42c5-824c-9e44cb2da98d/resourceGroups/many-models-rg/providers/Microsoft.MachineLearningServices/workspaces/mm-aml-wksp/environments/CliV2AnonymousEnvironment/versions/ad75df9ebcec64d82932d2816dbddd36\n",
      "      code: azureml:/subscriptions/9a729243-1221-42c5-824c-9e44cb2da98d/resourceGroups/many-models-rg/providers/Microsoft.MachineLearningServices/workspaces/mm-aml-wksp/codes/b961154b-8199-422f-8a2d-f14b7034dfc8/versions/1\n",
      "      id: /subscriptions/9a729243-1221-42c5-824c-9e44cb2da98d/resourceGroups/many-models-rg/providers/Microsoft.MachineLearningServices/workspaces/mm-aml-wksp/components/azureml_anonymous/versions/c714e8c8-9529-4137-b8e0-f75df90708ea\n",
      "      is_deterministic: true\n",
      "  distributed_inference:\n",
      "    type: parallel\n",
      "    inputs:\n",
      "      data_source:\n",
      "        path: ${{parent.jobs.partition_job.outputs.tabular_output_data}}\n",
      "      drop_cols: Advert,Store,Brand\n",
      "      experiment_names: many-models-parallel-training-job-mlflow-full\n",
      "      metric_name: test_rmse\n",
      "      date_col: WeekStarting\n",
      "      tracking_uri: azureml://centralus.api.azureml.ms/mlflow/v1.0/subscriptions/9a729243-1221-42c5-824c-9e44cb2da98d/resourceGroups/many-models-rg/providers/Microsoft.MachineLearningServices/workspaces/mm-aml-wksp\n",
      "    outputs:\n",
      "      output_dir:\n",
      "        mode: rw_mount\n",
      "        type: uri_folder\n",
      "    resources:\n",
      "      instance_count: 6\n",
      "    component:\n",
      "      name: distributed_inference\n",
      "      display_name: Many Model Predictions\n",
      "      description: parallel job to batch predict with many models\n",
      "      type: parallel\n",
      "      inputs:\n",
      "        data_source:\n",
      "          type: mltable\n",
      "          description: Input mltable with predefined partition format.\n",
      "          mode: direct\n",
      "        drop_cols:\n",
      "          type: string\n",
      "          description: Columns need to be dropped before training. Split by comma.\n",
      "        experiment_names:\n",
      "          type: string\n",
      "          description: Name of training experiement(s) to be used to select best model.\n",
      "            Split by comma.\n",
      "        metric_name:\n",
      "          type: string\n",
      "          description: Name of metric to be used to select best model, to be used\n",
      "            in mlflow query. i.e. test_remse\n",
      "        date_col:\n",
      "          type: string\n",
      "          description: Name of date column in data\n",
      "        tracking_uri:\n",
      "          type: string\n",
      "          description: tracking uri of mlflow server (aml workspace)\n",
      "      outputs:\n",
      "        output_dir:\n",
      "          type: uri_folder\n",
      "          mode: rw_mount\n",
      "      resources:\n",
      "        instance_count: 6\n",
      "      is_deterministic: true\n",
      "      error_threshold: -1\n",
      "      input_data: ${{inputs.data_source}}\n",
      "      logging_level: DEBUG\n",
      "      max_concurrency_per_instance: 2\n",
      "      mini_batch_error_threshold: 5\n",
      "      partition_keys:\n",
      "      - Store\n",
      "      - Brand\n",
      "      retry_settings:\n",
      "        timeout: 60\n",
      "        max_retries: 1\n",
      "      task:\n",
      "        type: run_function\n",
      "        code: /home/zacksoenen/Projects/many-models-azureml/src\n",
      "        entry_script: parallel_inference.py\n",
      "        program_arguments: '--drop_cols ${{inputs.drop_cols}} --experiment_names ${{inputs.experiment_names}}\n",
      "          --metric_name ${{inputs.metric_name}} --tracking_uri ${{inputs.tracking_uri}}\n",
      "          --date_col ${{inputs.date_col}} --output_dir ${{outputs.output_dir}} '\n",
      "        environment:\n",
      "          name: mm-remote-env-py37\n",
      "          id: azureml:/subscriptions/9a729243-1221-42c5-824c-9e44cb2da98d/resourceGroups/many-models-rg/providers/Microsoft.MachineLearningServices/workspaces/mm-aml-wksp/environments/mm-remote-env-py37/versions/2\n",
      "          description: Custom environment for many models\n",
      "          version: '2'\n",
      "          creation_context:\n",
      "            created_at: '2024-01-05T22:02:36.380184+00:00'\n",
      "            created_by: Zack Soenen\n",
      "            created_by_type: User\n",
      "            last_modified_at: '2024-01-05T22:02:36.380184+00:00'\n",
      "            last_modified_by: Zack Soenen\n",
      "            last_modified_by_type: User\n",
      "          image: mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04\n",
      "          conda_file:\n",
      "            channels:\n",
      "            - conda-forge\n",
      "            dependencies:\n",
      "            - python=3.7.6\n",
      "            - pip\n",
      "            - pip:\n",
      "              - azureml-mlflow\n",
      "              - mlflow\n",
      "              - mltable>=1.2.0\n",
      "              - azureml-dataset-runtime[pandas,fuse]\n",
      "              - azureml-telemetry\n",
      "              - pandas\n",
      "              - numpy\n",
      "              - wheel\n",
      "              - pillow\n",
      "              - azure-ai-ml\n",
      "              - azure-identity\n",
      "              - scikit-learn~=0.20.0\n",
      "              - cloudpickle==1.1.1\n",
      "              - tensorflow==2.1.4\n",
      "              - ipykernel\n",
      "            name: mm_remote\n",
      "          os_type: linux\n",
      "    error_threshold: -1\n",
      "    input_data: ${{inputs.data_source}}\n",
      "    logging_level: DEBUG\n",
      "    max_concurrency_per_instance: 2\n",
      "    mini_batch_error_threshold: 5\n",
      "    partition_keys:\n",
      "    - Store\n",
      "    - Brand\n",
      "    retry_settings:\n",
      "      timeout: 60\n",
      "      max_retries: 1\n",
      "    task:\n",
      "      type: run_function\n",
      "      code: /home/zacksoenen/Projects/many-models-azureml/src\n",
      "      entry_script: parallel_inference.py\n",
      "      program_arguments: '--drop_cols ${{inputs.drop_cols}} --experiment_names ${{inputs.experiment_names}}\n",
      "        --metric_name ${{inputs.metric_name}} --tracking_uri ${{inputs.tracking_uri}}\n",
      "        --date_col ${{inputs.date_col}} --output_dir ${{outputs.output_dir}} '\n",
      "      environment:\n",
      "        name: mm-remote-env-py37\n",
      "        id: azureml:/subscriptions/9a729243-1221-42c5-824c-9e44cb2da98d/resourceGroups/many-models-rg/providers/Microsoft.MachineLearningServices/workspaces/mm-aml-wksp/environments/mm-remote-env-py37/versions/2\n",
      "        description: Custom environment for many models\n",
      "        version: '2'\n",
      "        creation_context:\n",
      "          created_at: '2024-01-05T22:02:36.380184+00:00'\n",
      "          created_by: Zack Soenen\n",
      "          created_by_type: User\n",
      "          last_modified_at: '2024-01-05T22:02:36.380184+00:00'\n",
      "          last_modified_by: Zack Soenen\n",
      "          last_modified_by_type: User\n",
      "        image: mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04\n",
      "        conda_file:\n",
      "          channels:\n",
      "          - conda-forge\n",
      "          dependencies:\n",
      "          - python=3.7.6\n",
      "          - pip\n",
      "          - pip:\n",
      "            - azureml-mlflow\n",
      "            - mlflow\n",
      "            - mltable>=1.2.0\n",
      "            - azureml-dataset-runtime[pandas,fuse]\n",
      "            - azureml-telemetry\n",
      "            - pandas\n",
      "            - numpy\n",
      "            - wheel\n",
      "            - pillow\n",
      "            - azure-ai-ml\n",
      "            - azure-identity\n",
      "            - scikit-learn~=0.20.0\n",
      "            - cloudpickle==1.1.1\n",
      "            - tensorflow==2.1.4\n",
      "            - ipykernel\n",
      "          name: mm_remote\n",
      "        os_type: linux\n",
      "settings:\n",
      "  default_compute: azureml:mm-cpu-cluster\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Build Pipeline\n",
    "# Declare the overall input of the job.\n",
    "test_oj_data = Input(\n",
    "    path=test_data_asset.path,\n",
    "    type=AssetTypes.URI_FILE,\n",
    "    mode=InputOutputModes.RO_MOUNT,\n",
    ")\n",
    "\n",
    "# Declare pipeline structure.\n",
    "@pipeline(display_name=\"parallel inference - outpath\")\n",
    "def parallel_inference_pipeline(pipeline_input_data):\n",
    "    \n",
    "    # Declare 1st data partition command job.\n",
    "    partition_job = partition_data(\n",
    "        data_source=pipeline_input_data,\n",
    "        partition_keys=\"Store,Brand\",\n",
    "    )\n",
    "\n",
    "    # Declare 2nd parallel model training job.\n",
    "    parallel_inference = many_model_inference_with_partition_keys(\n",
    "        data_source=partition_job.outputs.tabular_output_data,\n",
    "        drop_cols=\"Advert,Store,Brand\",\n",
    "        experiment_names=\"many-models-parallel-training-job-mlflow-full\",\n",
    "        metric_name=\"test_rmse\",\n",
    "        date_col=\"WeekStarting\",\n",
    "        tracking_uri=azureml_tracking_uri\n",
    "    )\n",
    "    \n",
    "    # User could override parallel job run-level property when invoke that parallel job/component in pipeline.\n",
    "    # parallel_train.resources.instance_count = 5\n",
    "    # parallel_train.max_concurrency_per_instance = 2\n",
    "    # parallel_train.mini_batch_error_threshold = 10\n",
    "\n",
    "# Create pipeline instance\n",
    "inference_pipeline = parallel_inference_pipeline(pipeline_input_data=test_oj_data,)\n",
    "\n",
    "# Set pipeline level compute\n",
    "inference_pipeline.settings.default_compute = cpu_compute_target\n",
    "print(inference_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: the provided asset name 'mm-remote-env-py37' will not be used for anonymous registration\n",
      "Warning: the provided asset name 'mm-remote-env-py37' will not be used for anonymous registration\n",
      "Warning: the provided asset name 'mm-remote-env-py37' will not be used for anonymous registration\n",
      "Warning: the provided asset name 'mm-remote-env-py37' will not be used for anonymous registration\n",
      "\u001b[32mUploading src (0.01 MBs): 100%|██████████| 12062/12062 [00:00<00:00, 56374.10it/s]\n",
      "\u001b[39m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run Inference Pipeline\n",
    "pipeline_job = ml_client.jobs.create_or_update(\n",
    "    inference_pipeline,\n",
    "    experiment_name=\"many-models-parallel-inference-job\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coalesce outputs and save as ML data asset # Maybe not needed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Batch Endpoint \n",
    "# https://github.com/Azure/azureml-examples/blob/main/sdk/python/jobs/pipelines/1k_demand_forecasting_with_pipeline_components/automl-forecasting-demand-many-models-in-pipeline/automl-forecasting-demand-many-models-in-pipeline.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoke Batch endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow_client = mlflow.tracking.MlflowClient()\n",
    "azureml_tracking_uri = ml_client.workspaces.get(ml_client.workspace_name).mlflow_tracking_uri\n",
    "mlflow.set_tracking_uri(azureml_tracking_uri)\n",
    "\n",
    "reg = mlflow.sklearn.load_model(model_uri=f\"models:/1000_dominicks/latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Advert</th>\n",
       "      <th>Price</th>\n",
       "      <th>Week_Year</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WeekStarting</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1992-07-02</th>\n",
       "      <td>1027</td>\n",
       "      <td>dominicks</td>\n",
       "      <td>1</td>\n",
       "      <td>1.94</td>\n",
       "      <td>27</td>\n",
       "      <td>32732.850718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992-07-02</th>\n",
       "      <td>1017</td>\n",
       "      <td>dominicks</td>\n",
       "      <td>1</td>\n",
       "      <td>2.57</td>\n",
       "      <td>27</td>\n",
       "      <td>34955.292829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992-07-02</th>\n",
       "      <td>1025</td>\n",
       "      <td>tropicana</td>\n",
       "      <td>1</td>\n",
       "      <td>2.18</td>\n",
       "      <td>27</td>\n",
       "      <td>33124.575813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992-07-02</th>\n",
       "      <td>1007</td>\n",
       "      <td>dominicks</td>\n",
       "      <td>1</td>\n",
       "      <td>2.00</td>\n",
       "      <td>27</td>\n",
       "      <td>23280.121954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992-07-02</th>\n",
       "      <td>1012</td>\n",
       "      <td>tropicana</td>\n",
       "      <td>1</td>\n",
       "      <td>2.30</td>\n",
       "      <td>27</td>\n",
       "      <td>31458.285026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992-07-02</th>\n",
       "      <td>1023</td>\n",
       "      <td>tropicana</td>\n",
       "      <td>1</td>\n",
       "      <td>2.24</td>\n",
       "      <td>27</td>\n",
       "      <td>34618.230204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992-07-02</th>\n",
       "      <td>1025</td>\n",
       "      <td>minute_maid</td>\n",
       "      <td>1</td>\n",
       "      <td>2.02</td>\n",
       "      <td>27</td>\n",
       "      <td>30233.905537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992-07-02</th>\n",
       "      <td>1024</td>\n",
       "      <td>tropicana</td>\n",
       "      <td>1</td>\n",
       "      <td>2.19</td>\n",
       "      <td>27</td>\n",
       "      <td>30871.927871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992-07-02</th>\n",
       "      <td>1005</td>\n",
       "      <td>minute_maid</td>\n",
       "      <td>1</td>\n",
       "      <td>2.24</td>\n",
       "      <td>27</td>\n",
       "      <td>34618.230204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992-07-02</th>\n",
       "      <td>1007</td>\n",
       "      <td>tropicana</td>\n",
       "      <td>1</td>\n",
       "      <td>2.42</td>\n",
       "      <td>27</td>\n",
       "      <td>35239.127001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Store        Brand  Advert  Price  Week_Year   predictions\n",
       "WeekStarting                                                            \n",
       "1992-07-02     1027    dominicks       1   1.94         27  32732.850718\n",
       "1992-07-02     1017    dominicks       1   2.57         27  34955.292829\n",
       "1992-07-02     1025    tropicana       1   2.18         27  33124.575813\n",
       "1992-07-02     1007    dominicks       1   2.00         27  23280.121954\n",
       "1992-07-02     1012    tropicana       1   2.30         27  31458.285026\n",
       "1992-07-02     1023    tropicana       1   2.24         27  34618.230204\n",
       "1992-07-02     1025  minute_maid       1   2.02         27  30233.905537\n",
       "1992-07-02     1024    tropicana       1   2.19         27  30871.927871\n",
       "1992-07-02     1005  minute_maid       1   2.24         27  34618.230204\n",
       "1992-07-02     1007    tropicana       1   2.42         27  35239.127001"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "date_col = \"WeekStarting\"\n",
    "input_data = pd.read_csv(\"../data/oj_sim_sales/test_subset.csv\")\n",
    "drop_cols = [\"Advert\", \"Store\", \"Brand\"]\n",
    "\n",
    "# Prep Data\n",
    "input_data[date_col] = pd.to_datetime(input_data[date_col])\n",
    "input_data = input_data.set_index(date_col).sort_index(ascending=True)\n",
    "input_data = input_data.assign(Week_Year=input_data.index.isocalendar().week.values)\n",
    "\n",
    "X_test = input_data.drop(columns=drop_cols, errors=\"ignore\")\n",
    "\n",
    "# Make prediction\n",
    "predictions = reg.predict(X_test)\n",
    "\n",
    "# Combine prediction with input_data\n",
    "output_data = input_data.copy()\n",
    "output_data['predictions'] = predictions\n",
    "\n",
    "display(input_data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['many-models-parallel-training-job-mlflow-full']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"many-models-parallel-training-job-mlflow-full\".split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "many_models",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
