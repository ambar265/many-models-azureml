{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.ml import MLClient, Input, Output, load_component\n",
    "from azure.ai.ml.dsl import pipeline\n",
    "from azure.ai.ml.entities import BatchEndpoint, PipelineComponentBatchDeployment\n",
    "from azure.ai.ml.constants import AssetTypes, InputOutputModes\n",
    "from azure.ai.ml.parallel import parallel_run_function, RunFunction\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'USER': 'zacksoenen', 'VSCODE_WSL_EXT_LOCATION': '/mnt/c/Users/zacksoenen/.vscode/extensions/ms-vscode-remote.remote-wsl-0.81.8', 'WT_PROFILE_ID': '{51855cb2-8cce-5362-8f54-464b92b32386}', 'SHLVL': '2', 'HOME': '/home/zacksoenen', 'OLDPWD': '/mnt/c/Users/zacksoenen/AppData/Local/Programs/Microsoft VS Code', 'DBUS_SESSION_BUS_ADDRESS': 'unix:path=/run/user/1000/bus', 'WSL_DISTRO_NAME': 'Ubuntu', 'WAYLAND_DISPLAY': 'wayland-0', 'LOGNAME': 'zacksoenen', 'PULSE_SERVER': 'unix:/mnt/wslg/PulseServer', 'WSL_INTEROP': '/run/WSL/97485_interop', 'NAME': 'Code', '_': '/home/zacksoenen/miniconda3/envs/mm_remote/bin/python', 'TERM': 'xterm-color', 'PATH': '/home/zacksoenen/miniconda3/envs/mm_remote/bin:/home/zacksoenen/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/home/zacksoenen/miniconda3/envs/mm_remote/bin:/home/zacksoenen/miniconda3/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/usr/lib/wsl/lib:/mnt/c/Program Files/Microsoft SDKs/Azure/CLI2/wbin:/mnt/c/Windows/system32:/mnt/c/Windows:/mnt/c/Windows/System32/Wbem:/mnt/c/Windows/System32/WindowsPowerShell/v1.0:/mnt/c/Windows/System32/OpenSSH:/mnt/c/Program Files/Git/cmd:/mnt/c/Users/zacksoenen/AppData/Local/Microsoft/WindowsApps:/mnt/c/Users/zacksoenen/AppData/Local/Programs/Microsoft VS Code/bin:/mnt/c/Users/zacksoenen/AppData/Local/Programs/Hyper/resources/bin:/miniconda3/bin', 'XDG_RUNTIME_DIR': '/run/user/1000/', 'WT_SESSION': '78b66c4d-e2e4-484f-9bb4-115d51cee054', 'DISPLAY': ':0', 'LANG': 'C.UTF-8', 'SHELL': '/usr/bin/zsh', 'VSCODE_SERVER_TAR': '/mnt/c/Users/ZACKSO~1/AppData/Local/Temp/vscode-remote-wsl/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/vscode-server-stable-linux-x64.tar.gz', 'PWD': '/mnt/c/Users/zacksoenen/AppData/Local/Programs/Microsoft VS Code', 'HOSTTYPE': 'x86_64', 'WSL2_GUI_APPS_ENABLED': '1', 'WSLENV': 'ELECTRON_RUN_AS_NODE/w:WT_SESSION:WT_PROFILE_ID:\\n', 'VSCODE_HANDLES_SIGPIPE': 'true', 'ZSH': '/home/zacksoenen/.oh-my-zsh', 'PAGER': 'cat', 'LESS': '-R', 'LSCOLORS': 'Gxfxcxdxbxegedabagacad', 'LS_COLORS': 'rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=00:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.zst=01;31:*.tzst=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.wim=01;31:*.swm=01;31:*.dwm=01;31:*.esd=01;31:*.jpg=01;35:*.jpeg=01;35:*.mjpg=01;35:*.mjpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.webp=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=00;36:*.au=00;36:*.flac=00;36:*.m4a=00;36:*.mid=00;36:*.midi=00;36:*.mka=00;36:*.mp3=00;36:*.mpc=00;36:*.ogg=00;36:*.ra=00;36:*.wav=00;36:*.oga=00;36:*.opus=00;36:*.spx=00;36:*.xspf=00;36:', 'VIRTUAL_ENV_DISABLE_PROMPT': '1', 'CONDA_EXE': '/home/zacksoenen/miniconda3/bin/conda', '_CE_M': '', '_CE_CONDA': '', 'CONDA_PYTHON_EXE': '/home/zacksoenen/miniconda3/bin/python', 'CONDA_SHLVL': '2', 'CONDA_PREFIX': '/home/zacksoenen/miniconda3/envs/mm_remote', 'CONDA_DEFAULT_ENV': 'mm_remote', 'CONDA_PROMPT_MODIFIER': '(mm_remote) ', 'VSCODE_AMD_ENTRYPOINT': 'vs/workbench/api/node/extensionHostProcess', 'VSCODE_HANDLES_UNCAUGHT_ERRORS': 'true', 'VSCODE_NLS_CONFIG': '{\"locale\":\"en\",\"osLocale\":\"en\",\"availableLanguages\":{}}', 'VSCODE_CWD': '/mnt/c/Users/zacksoenen/AppData/Local/Programs/Microsoft VS Code', 'ELECTRON_RUN_AS_NODE': '1', 'VSCODE_IPC_HOOK_CLI': '/run/user/1000/vscode-ipc-c77d318b-348a-4592-a854-c53e0cb33bb0.sock', 'APPLICATION_INSIGHTS_NO_DIAGNOSTIC_CHANNEL': '1', 'PYTHONUNBUFFERED': '1', 'CONDA_ROOT': '/home/zacksoenen/miniconda3', 'PYTHONIOENCODING': 'utf-8', 'WORKSPACE_NAME': 'mm-aml-wksp', 'TENANT_ID': '16b3c013-d300-468d-ac64-7eda0820b6d3', 'SUBSCRIPTION_ID': '9a729243-1221-42c5-824c-9e44cb2da98d', 'RESOURCE_GROUP_NAME': 'many-models-rg', 'CONDA_PREFIX_1': '/home/zacksoenen/miniconda3', 'PYDEVD_IPYTHON_COMPATIBLE_DEBUGGING': '1', 'PYDEVD_USE_FRAME_EVAL': 'NO', 'CLICOLOR': '1', 'GIT_PAGER': 'cat', 'MPLBACKEND': 'module://matplotlib_inline.backend_inline', 'AZUREML_CURRENT_CLOUD': 'AzureCloud'}\n"
     ]
    }
   ],
   "source": [
    "# Initialize ML Client\n",
    "load_dotenv(find_dotenv(), override=True)\n",
    "\n",
    "# authenticate\n",
    "credential = DefaultAzureCredential(tenantid=os.environ.get('TENANT_ID'))\n",
    "\n",
    "# Get a handle to the workspace\n",
    "ml_client = MLClient(\n",
    "    credential=credential,\n",
    "    subscription_id = os.environ.get('SUBSCRIPTION_ID'),\n",
    "    resource_group_name = os.environ.get('RESOURCE_GROUP_NAME'),\n",
    "    workspace_name = os.environ.get('WORKSPACE_NAME'),\n",
    ")\n",
    "\n",
    "print(dict(os.environ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use remote environment created in step 1\n",
    "custom_env_name = \"mm-remote-env-py37\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "azureml://subscriptions/9a729243-1221-42c5-824c-9e44cb2da98d/resourcegroups/many-models-rg/workspaces/mm-aml-wksp/datastores/workspaceblobstore/paths/LocalUpload/724411e17666e66d19b8612b775b7707/test_subset.csv\n"
     ]
    }
   ],
   "source": [
    "# Acess data asset\n",
    "data_name = \"oj-sim-sales-test\"\n",
    "test_data_asset = ml_client.data.get(data_name, label='latest')\n",
    "print(test_data_asset.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data preparation component\n",
    "partition_data = load_component(source=\"../src/components/partition_data/partition_data.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_compute_target = \"mm-cpu-cluster\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "azureml_tracking_uri = ml_client.workspaces.get(ml_client.workspace_name).mlflow_tracking_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'run_time = datetime.today().strftime(\\'%Y%m%d%H%M%S\\')\\n\\noutput_dir = f\"many_model_outputs/{run_time}/\"\\nprint(output_dir)'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''run_time = datetime.today().strftime('%Y%m%d%H%M%S')\n",
    "\n",
    "output_dir = f\"many_model_outputs/{run_time}/\"\n",
    "print(output_dir)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create parallel inference step\n",
    "# Declare parallel job, with a run_function task\n",
    "many_model_inference_with_partition_keys = parallel_run_function(\n",
    "    name=\"distributed_inference\",\n",
    "    display_name=\"Many Model Predictions\",\n",
    "    description=\"parallel job to batch predict with many models\",\n",
    "    inputs=dict(\n",
    "        data_source=Input(\n",
    "            type=AssetTypes.MLTABLE,\n",
    "            description=\"Input mltable with predefined partition format.\",\n",
    "            mode=InputOutputModes.DIRECT,  # [Important] To use 'partition_keys', input MLTable is required to use 'direct' mode.\n",
    "        ),\n",
    "        drop_cols=Input(\n",
    "            type=\"string\",\n",
    "            description=\"Columns need to be dropped before training. Split by comma.\",\n",
    "        ),\n",
    "        experiment_names=Input(\n",
    "            type=\"string\",\n",
    "            description=\"Name of training experiement(s) to be used to select best model. Split by comma.\",\n",
    "        ),\n",
    "        metric_name=Input(\n",
    "            type=\"string\",\n",
    "            description=\"Name of metric to be used to select best model, to be used in mlflow query. i.e. test_remse\",\n",
    "        ),\n",
    "        date_col=Input(\n",
    "            type=\"string\",\n",
    "            description=\"Name of date column in data\",\n",
    "        ),\n",
    "        tracking_uri=Input(\n",
    "            type=\"string\",\n",
    "            description=\"tracking uri of mlflow server (aml workspace)\",\n",
    "        ),\n",
    "    ),\n",
    "    outputs=dict(\n",
    "        output_dir=Output(\n",
    "            type=AssetTypes.URI_FOLDER,\n",
    "            mode=InputOutputModes.RW_MOUNT,\n",
    "        )\n",
    "    ),\n",
    "    input_data=\"${{inputs.data_source}}\",  # Define which input data will be splitted into mini-batches\n",
    "    partition_keys=[\"Store\",\"Brand\"],  # Use 'partition_keys' as the data division method. This method requires MLTable input with partition setting pre-defined in MLTable artifact.\n",
    "    instance_count=6,  # Use X nodes from compute cluster to run this parallel job.\n",
    "    max_concurrency_per_instance=2,  # Create 2 worker processors in each compute node to execute mini-batches.\n",
    "    error_threshold=-1,  # Monitor the failures of item processed by the gap between mini-batch input count and returns. 'Many model training' scenario doesn't fit this setting and '-1' means ignore counting failure items by mini-batch returns.\n",
    "    mini_batch_error_threshold=5,  # Monitor the failed mini-batch by exception, time out, or null return. When failed mini-batch count is higher than this setting, the parallel job will be marked as 'failed'.\n",
    "    retry_settings=dict(\n",
    "        max_retries=1,  # Define how many retries when mini-batch execution is failed by exception, time out, or null return.\n",
    "        timeout=60,  # Define the timeout in second for each mini-batch execution.\n",
    "    ),\n",
    "    logging_level=\"DEBUG\", # DEBUG, INFO, WARNING, ERROR, ETC\n",
    "    task=RunFunction(\n",
    "        code=\"../src/\",\n",
    "        entry_script=\"parallel_inference.py\",\n",
    "        environment=ml_client.environments.get(custom_env_name, label=\"latest\"),\n",
    "        program_arguments=\"--drop_cols ${{inputs.drop_cols}} \"  # Passthrough input parameters into parallel_train script.\n",
    "        \"--experiment_names ${{inputs.experiment_names}} \"\n",
    "        \"--metric_name ${{inputs.metric_name}} \"\n",
    "        \"--tracking_uri ${{inputs.tracking_uri}} \"\n",
    "        \"--date_col ${{inputs.date_col}} \"\n",
    "        \"--output_dir ${{outputs.output_dir}} \",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "display_name: parallel inference output test3\n",
      "type: pipeline\n",
      "inputs:\n",
      "  pipeline_input_data:\n",
      "    mode: ro_mount\n",
      "    type: uri_file\n",
      "    path: azureml://subscriptions/9a729243-1221-42c5-824c-9e44cb2da98d/resourcegroups/many-models-rg/workspaces/mm-aml-wksp/datastores/workspaceblobstore/paths/LocalUpload/724411e17666e66d19b8612b775b7707/test_subset.csv\n",
      "outputs:\n",
      "  pipeline_output:\n",
      "    mode: rw_mount\n",
      "    type: uri_folder\n",
      "jobs:\n",
      "  partition_job:\n",
      "    type: command\n",
      "    inputs:\n",
      "      data_source:\n",
      "        path: ${{parent.inputs.pipeline_input_data}}\n",
      "      partition_keys: Store,Brand\n",
      "    component:\n",
      "      $schema: https://azuremlschemas.azureedge.net/latest/commandComponent.schema.json\n",
      "      name: partition_data\n",
      "      version: '1'\n",
      "      display_name: Partition data by keys\n",
      "      type: command\n",
      "      inputs:\n",
      "        data_source:\n",
      "          type: uri_file\n",
      "        partition_keys:\n",
      "          type: string\n",
      "      outputs:\n",
      "        tabular_output_data:\n",
      "          type: mltable\n",
      "      command: python partition_data.py --data_source ${{inputs.data_source}} --partition_keys\n",
      "        ${{inputs.partition_keys}} --tabular_output_data ${{outputs.tabular_output_data}}\n",
      "      environment: azureml:/subscriptions/9a729243-1221-42c5-824c-9e44cb2da98d/resourceGroups/many-models-rg/providers/Microsoft.MachineLearningServices/workspaces/mm-aml-wksp/environments/CliV2AnonymousEnvironment/versions/ad75df9ebcec64d82932d2816dbddd36\n",
      "      code: azureml:/subscriptions/9a729243-1221-42c5-824c-9e44cb2da98d/resourceGroups/many-models-rg/providers/Microsoft.MachineLearningServices/workspaces/mm-aml-wksp/codes/b961154b-8199-422f-8a2d-f14b7034dfc8/versions/1\n",
      "      id: /subscriptions/9a729243-1221-42c5-824c-9e44cb2da98d/resourceGroups/many-models-rg/providers/Microsoft.MachineLearningServices/workspaces/mm-aml-wksp/components/azureml_anonymous/versions/c714e8c8-9529-4137-b8e0-f75df90708ea\n",
      "      is_deterministic: true\n",
      "  distributed_inference:\n",
      "    type: parallel\n",
      "    inputs:\n",
      "      data_source:\n",
      "        path: ${{parent.jobs.partition_job.outputs.tabular_output_data}}\n",
      "      drop_cols: Advert,Store,Brand\n",
      "      experiment_names: many-models-parallel-training-job-mlflow-full\n",
      "      metric_name: test_rmse\n",
      "      date_col: WeekStarting\n",
      "      tracking_uri: azureml://centralus.api.azureml.ms/mlflow/v1.0/subscriptions/9a729243-1221-42c5-824c-9e44cb2da98d/resourceGroups/many-models-rg/providers/Microsoft.MachineLearningServices/workspaces/mm-aml-wksp\n",
      "    outputs:\n",
      "      output_dir: ${{parent.outputs.pipeline_output}}\n",
      "    resources:\n",
      "      instance_count: 6\n",
      "    component:\n",
      "      name: distributed_inference\n",
      "      display_name: Many Model Predictions\n",
      "      description: parallel job to batch predict with many models\n",
      "      type: parallel\n",
      "      inputs:\n",
      "        data_source:\n",
      "          type: mltable\n",
      "          description: Input mltable with predefined partition format.\n",
      "          mode: direct\n",
      "        drop_cols:\n",
      "          type: string\n",
      "          description: Columns need to be dropped before training. Split by comma.\n",
      "        experiment_names:\n",
      "          type: string\n",
      "          description: Name of training experiement(s) to be used to select best model.\n",
      "            Split by comma.\n",
      "        metric_name:\n",
      "          type: string\n",
      "          description: Name of metric to be used to select best model, to be used\n",
      "            in mlflow query. i.e. test_remse\n",
      "        date_col:\n",
      "          type: string\n",
      "          description: Name of date column in data\n",
      "        tracking_uri:\n",
      "          type: string\n",
      "          description: tracking uri of mlflow server (aml workspace)\n",
      "      outputs:\n",
      "        output_dir:\n",
      "          type: uri_folder\n",
      "          mode: rw_mount\n",
      "      resources:\n",
      "        instance_count: 6\n",
      "      id: /subscriptions/9a729243-1221-42c5-824c-9e44cb2da98d/resourceGroups/many-models-rg/providers/Microsoft.MachineLearningServices/workspaces/mm-aml-wksp/components/azureml_anonymous/versions/4ac33494-9509-45d5-8688-b4ce5f6a1a1f\n",
      "      is_deterministic: true\n",
      "      error_threshold: -1\n",
      "      input_data: ${{inputs.data_source}}\n",
      "      logging_level: DEBUG\n",
      "      max_concurrency_per_instance: 2\n",
      "      mini_batch_error_threshold: 5\n",
      "      partition_keys:\n",
      "      - Store\n",
      "      - Brand\n",
      "      retry_settings:\n",
      "        timeout: 60\n",
      "        max_retries: 1\n",
      "      task:\n",
      "        type: run_function\n",
      "        code: azureml:/subscriptions/9a729243-1221-42c5-824c-9e44cb2da98d/resourceGroups/many-models-rg/providers/Microsoft.MachineLearningServices/workspaces/mm-aml-wksp/codes/fbb33622-eb92-439a-8d84-b4b1b137a950/versions/1\n",
      "        entry_script: parallel_inference.py\n",
      "        program_arguments: '--drop_cols ${{inputs.drop_cols}} --experiment_names ${{inputs.experiment_names}}\n",
      "          --metric_name ${{inputs.metric_name}} --tracking_uri ${{inputs.tracking_uri}}\n",
      "          --date_col ${{inputs.date_col}} --output_dir ${{outputs.output_dir}} '\n",
      "        environment: azureml:/subscriptions/9a729243-1221-42c5-824c-9e44cb2da98d/resourceGroups/many-models-rg/providers/Microsoft.MachineLearningServices/workspaces/mm-aml-wksp/environments/mm-remote-env-py37/versions/2\n",
      "    error_threshold: -1\n",
      "    input_data: ${{inputs.data_source}}\n",
      "    logging_level: DEBUG\n",
      "    max_concurrency_per_instance: 2\n",
      "    mini_batch_error_threshold: 5\n",
      "    partition_keys:\n",
      "    - Store\n",
      "    - Brand\n",
      "    retry_settings:\n",
      "      timeout: 60\n",
      "      max_retries: 1\n",
      "    task:\n",
      "      type: run_function\n",
      "      code: azureml:/subscriptions/9a729243-1221-42c5-824c-9e44cb2da98d/resourceGroups/many-models-rg/providers/Microsoft.MachineLearningServices/workspaces/mm-aml-wksp/codes/fbb33622-eb92-439a-8d84-b4b1b137a950/versions/1\n",
      "      entry_script: parallel_inference.py\n",
      "      program_arguments: '--drop_cols ${{inputs.drop_cols}} --experiment_names ${{inputs.experiment_names}}\n",
      "        --metric_name ${{inputs.metric_name}} --tracking_uri ${{inputs.tracking_uri}}\n",
      "        --date_col ${{inputs.date_col}} --output_dir ${{outputs.output_dir}} '\n",
      "      environment: azureml:/subscriptions/9a729243-1221-42c5-824c-9e44cb2da98d/resourceGroups/many-models-rg/providers/Microsoft.MachineLearningServices/workspaces/mm-aml-wksp/environments/mm-remote-env-py37/versions/2\n",
      "settings:\n",
      "  default_compute: azureml:mm-cpu-cluster\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Build Pipeline\n",
    "# Declare the overall input of the job.\n",
    "test_oj_data = Input(\n",
    "    path=test_data_asset.path,\n",
    "    type=AssetTypes.URI_FILE,\n",
    "    mode=InputOutputModes.RO_MOUNT,\n",
    ")\n",
    "\n",
    "# Declare pipeline structure.\n",
    "@pipeline(display_name=\"parallel inference output test3\")\n",
    "def parallel_inference_pipeline(pipeline_input_data: Input(type=AssetTypes.MLTABLE)):\n",
    "    \n",
    "    # Declare 1st data partition command job.\n",
    "    partition_job = partition_data(\n",
    "        data_source=pipeline_input_data,\n",
    "        partition_keys=\"Store,Brand\",\n",
    "    )\n",
    "\n",
    "    # Declare 2nd parallel model training job.\n",
    "    parallel_inference = many_model_inference_with_partition_keys(\n",
    "        data_source=partition_job.outputs.tabular_output_data,\n",
    "        drop_cols=\"Advert,Store,Brand\",\n",
    "        experiment_names=\"many-models-parallel-training-job-mlflow-full\",\n",
    "        metric_name=\"test_rmse\",\n",
    "        date_col=\"WeekStarting\",\n",
    "        tracking_uri=azureml_tracking_uri\n",
    "    )\n",
    "    \n",
    "    return {\"pipeline_output\": parallel_inference.outputs.output_dir}\n",
    "\n",
    "    # User could override parallel job run-level property when invoke that parallel job/component in pipeline.\n",
    "    # parallel_train.resources.instance_count = 5\n",
    "    # parallel_train.max_concurrency_per_instance = 2\n",
    "    # parallel_train.mini_batch_error_threshold = 10\n",
    "\n",
    "# Create pipeline instance\n",
    "inference_pipeline = parallel_inference_pipeline(pipeline_input_data=test_oj_data,)\n",
    "\n",
    "# Set pipeline level compute\n",
    "inference_pipeline.settings.default_compute = cpu_compute_target\n",
    "print(inference_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Inference Pipeline\n",
    "pipeline_job = ml_client.jobs.create_or_update(\n",
    "    inference_pipeline,\n",
    "    experiment_name=\"many-models-parallel-inference-job\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Outputs ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifact azureml://subscriptions/9a729243-1221-42c5-824c-9e44cb2da98d/resourcegroups/many-models-rg/workspaces/mm-aml-wksp/datastores/workspaceblobstore/paths/azureml/56cd1dcb-57c0-491d-932f-8915bd8286f8/output_dir/ to ../data/oj_sim_sales/outputs/named-outputs/pipeline_output\n"
     ]
    }
   ],
   "source": [
    "# Download output data\n",
    "local_download_path = \"../data/oj_sim_sales/outputs/\"\n",
    "ml_client.jobs.download(name=pipeline_job.name, download_path=local_download_path, output_name=\"pipeline_output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1386"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WeekStarting</th>\n",
       "      <th>Advert</th>\n",
       "      <th>Price</th>\n",
       "      <th>Store</th>\n",
       "      <th>Brand</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1992-07-02</td>\n",
       "      <td>True</td>\n",
       "      <td>2.55</td>\n",
       "      <td>1028</td>\n",
       "      <td>minute_maid</td>\n",
       "      <td>35169.553746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1992-07-09</td>\n",
       "      <td>True</td>\n",
       "      <td>2.07</td>\n",
       "      <td>1028</td>\n",
       "      <td>minute_maid</td>\n",
       "      <td>31636.904183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1992-07-16</td>\n",
       "      <td>True</td>\n",
       "      <td>2.04</td>\n",
       "      <td>1028</td>\n",
       "      <td>minute_maid</td>\n",
       "      <td>31391.641231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1992-07-23</td>\n",
       "      <td>True</td>\n",
       "      <td>2.17</td>\n",
       "      <td>1028</td>\n",
       "      <td>minute_maid</td>\n",
       "      <td>28728.226342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1992-07-30</td>\n",
       "      <td>True</td>\n",
       "      <td>2.16</td>\n",
       "      <td>1028</td>\n",
       "      <td>minute_maid</td>\n",
       "      <td>24841.971246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  WeekStarting  Advert  Price  Store        Brand   predictions\n",
       "0   1992-07-02    True   2.55   1028  minute_maid  35169.553746\n",
       "1   1992-07-09    True   2.07   1028  minute_maid  31636.904183\n",
       "2   1992-07-16    True   2.04   1028  minute_maid  31391.641231\n",
       "3   1992-07-23    True   2.17   1028  minute_maid  28728.226342\n",
       "4   1992-07-30    True   2.16   1028  minute_maid  24841.971246"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read output data as pandas df\n",
    "\n",
    "glob_path = os.path.join(local_download_path +\"named-outputs/pipeline_output/*.csv\")\n",
    "output_files = glob.glob(glob_path)\n",
    "output_df = pd.concat((pd.read_csv(f) for f in output_files))\n",
    "\n",
    "display(len(output_df))\n",
    "display(output_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and Deploy Batch Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint name: manymodels-batch-endp-demo\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BatchEndpoint({'scoring_uri': 'https://manymodels-batch-endp-demo.centralus.inference.ml.azure.com/jobs', 'openapi_uri': None, 'provisioning_state': 'Succeeded', 'name': 'manymodels-batch-endp-demo', 'description': 'A many models batch inference endpoint', 'tags': {}, 'properties': {'BatchEndpointCreationApiVersion': '2022-05-01', 'azureml.onlineendpointid': '/subscriptions/9a729243-1221-42c5-824c-9e44cb2da98d/resourceGroups/many-models-rg/providers/Microsoft.MachineLearningServices/workspaces/mm-aml-wksp/batchEndpoints/manymodels-batch-endp-demo'}, 'print_as_yaml': True, 'id': '/subscriptions/9a729243-1221-42c5-824c-9e44cb2da98d/resourceGroups/many-models-rg/providers/Microsoft.MachineLearningServices/workspaces/mm-aml-wksp/batchEndpoints/manymodels-batch-endp-demo', 'Resource__source_path': None, 'base_path': '/home/zacksoenen/Projects/many-models-azureml/demo_notebooks', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7fe62c3a4d10>, 'auth_mode': 'aad_token', 'location': 'centralus', 'defaults': <azure.ai.ml._restclient.v2022_05_01.models._models_py3.BatchEndpointDefaults object at 0x7fe61c048310>})"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Batch Endpoint\n",
    "\n",
    "endpoint_name = \"manymodels-batch-endp-demo\"\n",
    "print(f\"Endpoint name: {endpoint_name}\")\n",
    "\n",
    "endpoint = BatchEndpoint(\n",
    "    name=endpoint_name,\n",
    "    description=\"A many models batch inference endpoint\",\n",
    ")\n",
    "\n",
    "ml_client.batch_endpoints.begin_create_or_update(endpoint).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PipelineComponent({'intellectual_property': None, 'auto_increment_version': False, 'source': 'REMOTE.WORKSPACE.COMPONENT', 'is_anonymous': False, 'auto_delete_setting': None, 'name': 'parallel_inference_pipeline', 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': '/subscriptions/9a729243-1221-42c5-824c-9e44cb2da98d/resourceGroups/many-models-rg/providers/Microsoft.MachineLearningServices/workspaces/mm-aml-wksp/components/parallel_inference_pipeline/versions/1', 'Resource__source_path': None, 'base_path': '/home/zacksoenen/Projects/many-models-azureml/demo_notebooks', 'creation_context': <azure.ai.ml._restclient.v2022_10_01.models._models_py3.SystemData object at 0x7fe532394910>, 'serialize': <msrest.serialization.Serializer object at 0x7fe61c838650>, 'version': '1', 'latest_version': None, 'schema': None, 'type': 'pipeline', 'display_name': 'parallel inference output test3', 'is_deterministic': False, 'inputs': {'pipeline_input_data': {'type': 'mltable', 'optional': False}}, 'outputs': {'pipeline_output': {'type': 'uri_folder'}}, 'yaml_str': None, 'other_parameter': {}, 'jobs': {}, 'job_types': {}, 'job_sources': {}, 'source_job_id': None})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define Pipeline Component\n",
    "pipeline_component = parallel_inference_pipeline().component\n",
    "\n",
    "# Register Pipeline Component for better tracking and versioning\n",
    "ml_client.components.create_or_update(pipeline_component)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class PipelineComponentBatchDeployment: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PipelineComponentBatchDeployment({'type': None, 'name': 'many-models-inference-deployment', 'description': None, 'tags': {'PipelineDeployment.ComponentId': '/subscriptions/9a729243-1221-42c5-824c-9e44cb2da98d/resourceGroups/many-models-rg/providers/Microsoft.MachineLearningServices/workspaces/mm-aml-wksp/components/parallel_inference_pipeline/labels/default'}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': '/home/zacksoenen/Projects/many-models-azureml/demo_notebooks', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7fe62c247ad0>, 'component': '/subscriptions/9a729243-1221-42c5-824c-9e44cb2da98d/resourceGroups/many-models-rg/providers/Microsoft.MachineLearningServices/workspaces/mm-aml-wksp/components/parallel_inference_pipeline/labels/default', 'endpoint_name': 'manymodels-batch-endp-demo', 'settings': None, 'job_definition': None})"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Deployment\n",
    "deployment = PipelineComponentBatchDeployment(\n",
    "    name=\"many-models-inference-deployment\",\n",
    "    description=\"A many models deployment.\",\n",
    "    endpoint_name=endpoint_name,\n",
    "    component=pipeline_component,\n",
    "    settings={\"default_compute\": cpu_compute_target},\n",
    ")\n",
    "\n",
    "ml_client.batch_deployments.begin_create_or_update(deployment).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Name</th><th>Type</th><th>Status</th><th>Details Page</th></tr><tr><td>manymodels-batch-endp-demo</td><td>5eefd257-6f55-4240-acda-c2bfb1fc1781</td><td>pipeline</td><td>Failed</td><td><a href=\"https://ml.azure.com/runs/5eefd257-6f55-4240-acda-c2bfb1fc1781?wsid=/subscriptions/9a729243-1221-42c5-824c-9e44cb2da98d/resourcegroups/many-models-rg/workspaces/mm-aml-wksp&amp;tid=16b3c013-d300-468d-ac64-7eda0820b6d3\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td></tr></table>"
      ],
      "text/plain": [
       "PipelineJob({'inputs': {}, 'outputs': {}, 'jobs': {}, 'component': PipelineComponent({'intellectual_property': None, 'auto_increment_version': False, 'source': 'REMOTE.WORKSPACE.JOB', 'is_anonymous': True, 'auto_delete_setting': None, 'name': 'azureml_anonymous', 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': '/home/zacksoenen/Projects/many-models-azureml/demo_notebooks', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7fe532ae6310>, 'version': '1', 'latest_version': None, 'schema': None, 'type': 'pipeline', 'display_name': 'green_answer_vq7yv24s', 'is_deterministic': None, 'inputs': {}, 'outputs': {}, 'yaml_str': None, 'other_parameter': {}, 'jobs': {}, 'job_types': {}, 'job_sources': {}, 'source_job_id': None}), 'type': 'pipeline', 'status': 'Failed', 'log_files': None, 'name': '5eefd257-6f55-4240-acda-c2bfb1fc1781', 'description': None, 'tags': {'azureml.deploymentname': 'many-models-inference-deployment', 'azureml.batchrun': 'true', 'azureml.jobtype': 'azureml.pipelinejob'}, 'properties': {'azureml.runLineageType': 'batchDeployment', 'azureml.deploymentname': 'many-models-inference-deployment', 'azureml.endpointname': 'manymodels-batch-endp-demo', 'azureml.SourceComponentId': '/subscriptions/9a729243-1221-42c5-824c-9e44cb2da98d/resourceGroups/many-models-rg/providers/Microsoft.MachineLearningServices/workspaces/mm-aml-wksp/components/parallel_inference_pipeline/labels/default', 'azureml.DevPlatv2': 'true', 'azureml.DatasetAccessMode': 'Asset', 'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'BatchDeployment', 'runType': 'HTTP', 'azureml.parameters': '{}', 'azureml.sourcepipelinerunid': '625e0599-ec3f-4fd0-a5fe-10372882d675', 'azureml.continue_on_step_failure': 'True', 'azureml.continue_on_failed_optional_input': 'True', 'azureml.enforceRerun': 'False', 'azureml.defaultComputeName': 'mm-cpu-cluster', 'azureml.defaultDataStoreName': 'workspaceblobstore', 'azureml.pipelineComponent': 'pipelinerun'}, 'print_as_yaml': True, 'id': '/subscriptions/9a729243-1221-42c5-824c-9e44cb2da98d/resourceGroups/many-models-rg/providers/Microsoft.MachineLearningServices/workspaces/mm-aml-wksp/jobs/5eefd257-6f55-4240-acda-c2bfb1fc1781', 'Resource__source_path': None, 'base_path': '/home/zacksoenen/Projects/many-models-azureml/demo_notebooks', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7fe53238c690>, 'serialize': <msrest.serialization.Serializer object at 0x7fe61c182cd0>, 'display_name': 'green_answer_vq7yv24s', 'experiment_name': 'manymodels-batch-endp-demo', 'compute': None, 'services': {'Tracking': {'endpoint': 'azureml://centralus.api.azureml.ms/mlflow/v1.0/subscriptions/9a729243-1221-42c5-824c-9e44cb2da98d/resourceGroups/many-models-rg/providers/Microsoft.MachineLearningServices/workspaces/mm-aml-wksp?', 'type': 'Tracking'}, 'Studio': {'endpoint': 'https://ml.azure.com/runs/5eefd257-6f55-4240-acda-c2bfb1fc1781?wsid=/subscriptions/9a729243-1221-42c5-824c-9e44cb2da98d/resourcegroups/many-models-rg/workspaces/mm-aml-wksp&tid=16b3c013-d300-468d-ac64-7eda0820b6d3', 'type': 'Studio'}}, 'settings': {}, 'identity': None, 'default_code': None, 'default_environment': None})"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Invoke Batch endpoint\n",
    "input_data = test_oj_data\n",
    "\n",
    "endp_job = ml_client.batch_endpoints.invoke(\n",
    "    endpoint_name=endpoint.name,\n",
    "    deployment_name=deployment.name,\n",
    "    inputs={\"pipeline_input_data\": input_data},\n",
    ")\n",
    "\n",
    "ml_client.jobs.get(endp_job.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "many_models",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
